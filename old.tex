\section{CI/CD Framework for the Urban Building Pilot}
The Urban Building application leverages a sophisticated software stack centered around the Feel++ framework. This section  explains how the CI/CD framework facilitates efficient development and deployment.

\subsection{CI/CD Using GitHub Actions and Docker}
The development and deployment of the Urban Building pilot are streamlined through a CI/CD pipeline that utilizes GitHub Actions and Docker. This setup ensures that the software development lifecycle is robust, with continuous integration and deployment enhancing productivity and reliability. 

GitHub Actions automate workflows to compile, test, and validate code changes in real-time, facilitating rapid development cycles and ensuring code quality. Additionally, Docker provides a containerized environment where Feel++ and its dependencies are encapsulated, ensuring consistent operations across different computing environments. Docker images are specifically tailored for various systems, accommodating a wide range of deployment scenarios.
    
We start with the CI/CD DevOps for Feel++. 
The workflow is central to developing and maintaining the Feel++ framework, ensuring that updates and enhancements are efficiently integrated and deployed across all projects utilizing Feel++. Below we outline the structured approach taken using GitHub Actions, Docker, and Apptainer.

Feel++ utilizes a robust environment setup that is continuously integrated and uploaded to the GitHub Container Registry (ghcr.io). The environment includes configurations for multiple operating systems and computational backends:
\textit{(i)} first continuous integration (CI) environments for Ubuntu 22.04, Ubuntu 20.04, Ubuntu 24.04, and Debian 12 and \textit{(ii)} scheduled integration (SCI) environments including Spack-based configurations for MPI and other computational libraries.

The CI/CD pipelines for Feel++ are triggered through various mechanisms to ensure responsiveness and up-to-date compatibility: \textit{(i)} \textbf{Pull Requests and Merges:} Triggers the CI to ensure that new code integrations meet all tests and standards, \textit{(ii)} \textbf{Graphical User Interface (GUI):} Allows developers to manually trigger pipelines through a GUI, facilitating quick deployments or tests and \textit{(iii)} \textbf{Scheduled Runs:} Ensures regular updates and maintenance checks are performed, even during periods of low manual activity.

\subsection{Docker and Apptainer Workflow}
\begin{itemize}
    \item \textbf{Docker Images:} All Docker images are tailored for specific system requirements and are uploaded to ghcr.io. These images are then utilized to ensure consistent environments across various deployment scenarios.
    \item \textbf{Apptainer Images:} Apptainer (formerly Singularity) provides a secure way to handle containers. Images created for Apptainer ensure that Feel++ can be deployed in a secure and reproducible manner across HPC environments without requiring root privileges.
\end{itemize}



\subsection{Utilization by Projects}
\begin{itemize}
    \item Both Docker and Apptainer images are extensively used by projects built upon the Feel++ framework. These projects benefit from the robust, tested, and secure environments that Feel++ CI/CD practices ensure.
\end{itemize}

\section{HPC Operations (HPC-Ops)}
Innovative HPC-Ops practices are integral to the deployment and benchmarking processes of the Feel++ framework, enabling it to perform consistently across diverse high-performance computing (HPC) systems. This section details the strategies and tools used for large-scale computational benchmarks and reproducibility assurance.

\subsection{Benchmarking and Reproducibility}
Upon successful updates or integrations, large-scale benchmarking is triggered to evaluate the performance and scalability of the Feel++ applications. These benchmarks are crucial for:
\begin{itemize}
    \item Validating the computational correctness and efficiency across platform variations.
    \item Ensuring that performance optimizations are effective and do not introduce errors.
\end{itemize}

\subsection{Integration with HPC Systems}
\begin{itemize}
    \item \textbf{Apptainer Images:} Central to the HPC-Ops strategy, Apptainer (formerly Singularity) images are used to encapsulate the computing environment, making it portable and reproducible across all HPC platforms. These images are maintained and updated on GitHub Container Registry (ghcr.io).
    \item \textbf{HPC Systems:} The workflow is designed to integrate with several EuroHPC systems such as LUMI, Karolina, Meluxina, and Discoverer, as well as other significant HPC infrastructures including local systems like Gaya and global platforms such as PSNC/Eagle.
\end{itemize}

\subsection{Automation Tools}
Our automation toolchain employs several sophisticated technologies to enhance the deployment and management of high-performance computing environments. Reframe, a framework for defining and managing systematic benchmarks, ensures reproducibility across various HPC environments, simplifying performance and scalability testing on these complex systems. GitHub Actions automates the CI/CD pipeline, enabling consistent and reliable deployment of code changes across all platforms. This tool integrates directly with our GitHub repositories to automate, customize, and execute software development workflows efficiently. Furthermore, SLURM, crucial for scheduling and managing jobs on many integrated HPC systems, includes a REST API that facilitates efficient resource management and job queuing by allowing programmable job submissions and monitoring directly from CI workflows. Apptainer, formerly known as Singularity, rounds out our toolset by providing a containerization solution specifically tailored for HPC applications, enabling the creation of portable and reproducible computing environments crucial for maintaining consistency across different systems. Together, these tools form the backbone of our automated processes, driving the efficiency and reliability of our Urban Building simulations on diverse computational infrastructures.


The challenges encountered in integrating such a diverse array of systems and the innovative solutions developed, include
\textit{(i)} ensuring compatibility and performance across different HPC architectures and \textit{(ii)} automating the deployment and scaling of complex simulations securely and efficiently.

The HPC-Ops framework developed for Feel++ represents a significant advancement in the field of computational sciences, driving forward the capabilities for large-scale scientific computations. It sets a benchmark for how modern software frameworks can integrate with advanced HPC infrastructures to enhance computational research and applications.

\subsection{Urban Building DevOps Framework}


GitHub serves as the central repository hosting the source code, with robust version control to manage contributions and revisions effectively.

\subsection{Continuous Integration and Deployment (CI/CD)}
\begin{itemize}
    \item \textbf{Feel++ Environment Setup}: Leveraging Docker and Apptainer containers ensures a consistent and reproducible environment across different systems. Docker images are tailored to support various operating systems and configurations, which are regularly updated and pushed to GitHub Container Registry (ghcr.io).
    \item \textbf{Automated Testing and Deployment}:
    \begin{itemize}
        \item GitHub Actions automates workflows for testing, building, and deploying applications. This includes automatic updates for documentation hosted on GitHub Pages.
        \item Integration with GitHub ensures that code changes trigger automated workflows that build and test the software across multiple platforms.
    \end{itemize}
\end{itemize}

\subsection{Packaging}
The software is packaged into Wheel for Python libraries and DEB packages for Debian/Ubuntu systems. These packages facilitate easy distribution and installation of the software. Spack, a flexible package manager, is used for managing the installations of software on HPC systems, ensuring that dependencies are handled correctly across different environments.

\subsection{Deployment on HPC Systems}
Utilizing Apptainer (formerly Singularity) containers enhances portability and security, allowing the Urban Building simulations to be deployed seamlessly on various HPC systems including local clusters like Gaya and EuroHPC systems such as LUMI, Karolina, Meluxina, and Discoverer. The use of SLURM for job scheduling on these HPC systems ensures efficient management of computational resources.

\subsection{Documentation and Training}
Documentation is automatically generated and updated with each code push to the master branch, ensuring that all features and changes are well-documented. The documentation includes comprehensive guides on installation, configuration, and usage, along with API documentation generated directly from the source code.

\subsection{Benchmarking and Quality Assurance}
Continuous benchmarking is integrated into the CI/CD pipeline, triggering large-scale benchmark tests upon successful preliminary tests. This ensures that the software performs optimally across all supported platforms before any releases. Quality assurance practices include code reviews, unit testing, and integration testing, all automated through GitHub Actions.

By leveraging these DevOps practices, the Urban Building pilot ensures that it remains robust, scalable, and adaptable to new HPC technologies and architectures, ultimately supporting the HiDALGO2 project's goals of advancing urban simulation technologies at a global scale.


\section{Urban Building HPC Operations}

The Urban Building High-Performance Computing (HPC) Operations outline a sophisticated workflow that integrates continuous integration and deployment (CI/CD) with advanced benchmarking strategies. These operations are crucial for ensuring the performance, scalability, and reliability of the Urban Building simulations on various HPC systems.

\subsection{HPC Benchmarking CI/CD}
The benchmarking CI/CD pipeline is triggered upon successful completion of the standard CI/CD processes, which include automated testing and validation of the software. New Apptainer containers are created and made available, facilitating deployment on diverse computational resources.

\begin{itemize}
    \item \textbf{Automated Testing:} Once new changes are integrated and the standard CI/CD pipeline succeeds, larger scale tests are automatically initiated on a designated HPC node with significant computational resources, for example, 128 cores.
    \item \textbf{Manual and Scheduled Testing:} For extensive validation, tests can also be manually triggered or scheduled to run at predefined intervals. This flexibility allows for comprehensive performance assessments under varying loads and configurations.
\end{itemize}

\subsection{Use of Reframe}
Reframe is employed as the regression testing framework, essential for verifying the stability and performance regressions of the software across updates. It enables:
\begin{itemize}
    \item Systematic execution of test suites across different HPC systems.
    \item Collection and analysis of performance data to monitor software behavior and performance trends over time.
\end{itemize}

\subsection{Integration with HPC Systems}
\begin{itemize}
    \item \textbf{EuroHPC Integration:} The Urban Building pilot is integrated with several EuroHPC systems like LUMI, Karolina, Meluxina, and Discoverer, enhancing the capability to perform simulations at an unprecedented scale.
    \item \textbf{Local and International HPC Systems:} The framework also supports deployment on local HPC systems (e.g., Gaya) and international platforms like PSNC's Eagle, ensuring wide accessibility and usability of the software.
\end{itemize}

All performance results are automatically captured and uploaded to the HiDALGO2 portal. This ensures that \textit{(i)} Stakeholders have real-time access to performance reports and \textit{(ii)} decision-makers can review comprehensive data to guide further optimization and development efforts.

\subsection{Deployment and Scalability}
\begin{itemize}
    \item \textbf{Containerized Deployment:} Utilizing Docker and Apptainer containers ensures that the Urban Building application is portable and consistent across various computing environments.
    \item \textbf{Scalable Benchmarking:} The capability to scale tests according to the available hardware and project requirements is critical, allowing the team to simulate urban environments of varying complexities.
\end{itemize}

This comprehensive HPC operations framework underlines the commitment of the HiDALGO2 project to leveraging cutting-edge computational technologies to enhance urban simulation studies, ensuring high performance and accuracy of the Urban Building models.
